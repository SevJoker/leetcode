0: 自我介绍
	丁贤钊，15年毕业于大连理工软件学院。工作经历主要分三段
	第一段是去了一个学长创建的创业公司，面向oto停车场的项目，带了9个月就融资有问题
	第二段是一家叫作业黑子的k12教育公司，主要业务是将老师补作业学生答题的场景从线上搬到线下，主要承担的事主要是做题库相关的建设，爬取清晰，以及实现相关策略服务，比如智能出题，ocr等
	19年来到滴滴，在业务中台的交易中心呆了5年，部门定位是面向滴滴各个业务线提供通用的交易相关的服务支持，比如收银支付，计价，营销能力等
	开始两年在账单计价组，负责滴滴打车的各个业务线的司乘账单的实时计算，包括预估，实时计价，完单计价等
	后面三年主要在营销组，主要负责滴滴所有业务线的底层优惠能力的计算，包括优惠中心券卡金等系统。


1. 营销稳定性建设怎么做的？难点是啥，解法是啥？资金安全是如何处理的？
	中台因为服务全部业务，而且涉及交易资金相关，稳定性的重要性不用说。
	拆解思路主要两点，将发生，促恢复。
	将发生主要抓手
		1. 方案review，代码cr   
		2. 限流配置
		3. 自动防火，弱依赖改造
		4. 同城双活改造（多机房改造）
			--具体方案 多机房部署 包括mysql
	促恢复主要分几个阶段来找抓手
		1. 早发现
			系统监控  业务监控 
				核心思路，保证大的业务线有业务大盘监控，针对每个优惠都有相应基础的发放+核销监控
						预估完单一致性对比（类似对账）
						业务大盘监控
						极端值
					针对核心链路，比如呼返需要单独构建业务大盘监控
			系统报警  业务报警
				--具体方案 可以做一些系统性规范化的统一处理，报警自动化处理保证不漏，保证报警够全优先
		2. 快定位
			工具建设，错误码优化等
		3. 早止损
			降级预案
				弱依赖降级
					自动降级
					主动熔断
				强依赖降级方案
					业务降级手段--优先保核心链路（履约交易），再保用户不受损（多付钱），最后保用户体验（给文案提示等）

			后门接口
				- 业务降级，修改后台数据等
		4. 快善后
			工具化沉淀




2. 说一下账单计价的业务流程？整体技术架构是什么样的？
	计价的业务主要是负责网约车场景下各个业务线包括国际化的价格计算，包括预估计价，行程中实时计价，完单计价等功能。计价的场景和模式很多变，包括实时计价，一口价，多因素一口价等等模式。难点主要是1.计算量大 qps10w的情况下保证稳定性  2.需求方多，业务复杂度高  3. 价格计算要求准确度高。  业务复杂度 体现在不同城市不同品类的计价模式都会有不同诉求，品类约十几种。还有不同业务场景下的费用计算。

	技术架构主要分b端 和 c端。b端是一个配置平台，来处理计价的配置管理。
	c端主要是四个服务   plutus基础计价   cratos 个性化计价聚合平台  talos 权益系统   dealer渲染模块。 下游依赖主要是 地图  业务特殊计价，mpt动调，等等。

	其中服务都是双机房部署，包括下游的redis mysql都是双机房。plutus主要依赖redis + fusion。b端的配置平台通过阿波罗+彩虹桥发布文件同步到线上，其中计价配置因为对版本要求比较高，而且文件较大，所以需要中间程序检测打包通过后发布到线上。计价以10分钟为最小单元，分段计价，以开始计价时间读取的计价版本为准，线上需要加载全部版本的计价配置。每一份计价配置都会有版本号。
	服务发现统一走的滴滴自研的disf系统，在配置平台配置注册，odin上线打包的时候会检测下游依赖关系，disf会读取相关依赖 做文件推送。最开始是sdk集成的方式去，最近会逐步改成mesh，降低业务代码复杂度。


	todo
		基础计价的简单流程实现
		个性化计价的流程实现
		开发平台的流程实现



3. 计价服务的难点是啥？解法是啥？你在其中做了哪些
	难点：1.吞吐高，且要保证稳定性。 2 业务复杂度。不同国家不同城市不同品类不同场景下的计价诉求都不一样。  3 加个计价要求精度高（司乘敏感）

	解法
		1. 自身服务上云，弹性可伸缩，下游依赖主要是redis ，高吞吐，且redis集群部署，集群也保证可弹性伸缩且有主备。
		2. 配置化处理+开放平台。 针对不同计价模式提供不同的配置模板，可以进行计费配置。同时针对不同业务的个性化计费诉求，提供一个开放平台，类似在计价流程中提供一个勾子，让业务可以自行注入相关费用项
		3. 费用相关的底层函数统一封装，保证计算口径的一致性。（针对多国家做了i18n集成，cgo调用so），对边界情况的各种判断抹零处理，保证账平&不出天价&负账单。对计费流程中会有各种策略处理，来保证行程中计费的准确性。
	我在其中
		策略调整，比如开始计价点策略（因为开始计价只有一个点，很容易偏移）所以锚定了发单点和司机最后一个点的距离作为参考，来修正开始计价点
				比如附加费各种阈值判断。避免司机错输
		配置化在分账优化中也是做了很多处理，对分账能力进行完全配置化处理
		redis集群升级。从之前codis架构升级为 kedis架构（具体架构区分？）
			codis是之前豌豆荚开源的proxy架构，扩容复杂
			kedis是redis cluster架构
			其中主要是有些命令会不兼容


4. 营销的业务流程？整体架构是什么样的？
	营销的业务主要是负责滴滴所有业务下的优惠的底层能力。优惠如果简单从流向来划分的话，可以简单分为发和用。用户怎么获得这个优惠，用户怎么使用这个优惠。前者主要是各个业务增长团队需要处理的业务场景。中台涉及的场景很多，主要聚焦在后者，也就是使用场景。使用的场景主要涉及 预估  完单支付链路  还有一些特殊的组合场景比如搭售，比如呼返。我们这边对外提供的能力 1 针对发对外提供相应的绑定接口即可。 2. 针对核销  提供不同优惠渠道在不同业务场景下的叠加互斥抵扣计算，优惠渠道包括 券 卡 积分 福利金  随单立减等等优惠项。包括预估吐出可抵扣金额  以及后面的优惠冻结核销。需要保证状态的一致性。

	整体架构这边主要分四个模块
	b端配置平台
		统一的配置中心。统一提供配置能力，面向运营+技术+pm，提供优惠产品的配置  产品线的接入，以及各种核销规则+文案展示的配置能力

	c端主要由优惠中心  coupon  vcoin 三个系统提供四种模型能力。
	功能上 coupon提供 券 + 卡+随单的模型能力 vcoin提供 虚币类资产能力 这四种模型可以配置生成各种优惠产品，提供相应的规则过滤&计算能力，还有单优惠产品的核销逻辑。 优惠中心负责各个优惠产品也就是不同优惠渠道的叠加和互斥逻辑计算。
	架构师，每个服务都是双机房部署，集成了mesh部署，其中，券的数据量最大，db是16分片 双机房部署。
	下游依赖还有一些反作弊，标签，特征等。

	服务发现同上，用公司的disf。


5. 难点在哪？解法是啥？
	描述是现有架构，在此之前，整体架构较为混乱。比如虚币系统有类似的系统4-6个都是从业务下沉下来的，需要做系统合并&数据迁移。此外系统的整体配置化能力也很弱，需求迭代效率堪忧
	难点主要是
	1. 从团队来看
		- 人效低，配置化程度很低
	2. 从系统能力看
		- 系统之间比较离散，关联性较弱
		- 配置化能力比较弱，业务需求迭代慢，自助率第
		- 类似系统较多，且技术栈杂（java，php），不方便管理
	解法：
		人效问题：
			case工具化，多打埋点，对相关链路提供工具，让业务自助，减少无效提问，同时找了一个外包，专职值周，大大减少了值周压力
		系统问题
			配置化问题 
				通过能力抽象，模板化，对相关改动进行抽象，翻看历史需求，主要集中再规则修改已经相关字段展示字段的变化，这些其实可以抽象出配置化的工具进行协议打通，来实现需求的完全配置化。
			系统多
				通过能力聚合，实现一个虚币系统去承接所有虚币类的能力，需要做相关的逻辑迁移 &数据迁移
			系统离散问题
				需要做顶层设计，锚定一些业务主线，抽离出一些公共的通用属性，用来把系统进行串联，比如品类，每个系统都需要做品类接入，配置很离散，用户使用成本也很高，比如定义优惠产品，并打通协议，通过一份配置就能串联整个核销链路，让整个营销看起来更产品化一点。


6. golang gmp调度模型是什么？ 
todo
	g:goroutine
	m:线程 可以理解为内核线程
	p:调度器
	p负责装载g然后交给绑定的m执行具体操作
	p有自己的局部队列，也有全局的队列，优先会把g放在本地的具备队列。
	核心的设计策略有三个 
	1. 复用策略：复用线程
		偷取策略，p没有g，会从其他队列里偷取，
		移交机制，g被占用阻塞时，线程会释放p，p会继续找线程执行其他g
	2. 并行
		多cpu
	3. 抢占
		go里面一个goroutine最多执行100ms就必须让出cpu，防止其他goroutine无资源
	4. 全局队列
		本地队列找不到，去其他队列也找不到，会去全局队列找
	gmp要解决的问题有两个
		1. cpu调度切换进程消耗过大
		2. 内存占用过高（线程占用4mb，协程2kb）

7. 线程和协程的区别？
	进程：运行在系统上的一个独立程序，有独立的空间，是系统资源分配和调度的基本单位。各进程空间相互隔离              进程独立的栈和堆，调度由系统
	线程：线程是程序执行流的最小单元，一个进程可以由一个或多个线程组成，各个线程之间共享程序的内存空间，以及相关资源。   线程拥有独立的栈和共享的堆，调度归系统
	协程：用户态的轻量级线程实现。  共享堆，不共享栈，协程调度由用户控制
	协程优点
		- 调度更优秀，线程是抢占式，协程是协作式，且不需要做用户态切换到内核态
		- 占用内存更小

8. golang 垃圾回收机制是啥？
https://liangyaopei.github.io/2021/01/02/golang-gc-intro/
	三色标记法（标记清除法）
		正常标记清除工作流程
			1. 标记阶段 - 从根节点出发，扫描并标记各个存活的对象
			2. 清除阶段 - 遍历堆上所有对象，回收未被标记的垃圾对象并将回收的内存放入空闲链表
		三色标记法
			1. 白色  可删除  2. 灰色 中间阶段  3. 黑色  有引用的
			标记流程
				1. 开始均为白色
				2. 将根节点标记为灰色，放入待处理队列
						（根对象包括  1.全局变量， 2.执行栈，执行栈上的变量以及指向分配到堆上的指针   3.寄存器 指针指向堆内存区块）
				3. 从队列获取所有灰色，将起引用的对象标记为灰色，并放入待处理队列，自身标记为黑色
				4. 重复过程3 直到没有灰色，此时白色为全部需要回收对象。
			问题：
				需要stw，导致gc影响程序效率
			引入屏障技术（降低stw的时间）
				所谓屏障技术就是在标记环节，对象有操作时需要额外做的处理。
				插入写屏障
					任何引用操作都标记为灰色。即A新增引用B 将b置为灰色
						仅仅堆上操作，栈上操作太频繁
				删除屏障
					被删除的对象，如果自身为灰色或者白色 则标记为灰色
						也就是回收效率低一些
				混合写屏障
					主要是栈上操作
					被删除的对象都标记为灰色（堆+栈）
					添加的对象都为灰色（堆+栈）
					栈上所有可达对象都为黑色
					栈上所有新增对象都为黑色

	python
		1.计数清除法。每个对象都有计数，计数归0则清除。
		2.标记清除。对于循环引用的问题则需要标记清除来补充处理，从根节点出发，标记所有可达对象，不可达即可清除
		3.分代收集。优化效率，分三代处理，g0 g1 g2  活的越长的对象 后面触发gc的周期越来越长
	


9. golang 内存分配是什么做的？
	https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/
	内存基本分配模式
		线性分配器
		空闲链表分配器
	分级分配
		线程缓存分配 是用于分配内存的机制。核心理念就是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略。
	todo

10. mq是怎么防止消息丢失？有序性如何保证？
	有序性
		同一个partition 使用wal 保证fifo队列先进先出
		发送消息指定partition
			多个partition则无法做到
		消费消息一个消费者只能消费一个partition的消息

	防止消息丢失
		1. 生产者防止消息丢失
			设置ack，同步阻塞等待成功
			重试机制
		2. broker 即mq本身防止丢失
			- 持久化日志 wal写日志成功后返回ack
			- ISR列表  副本同步成功后返回ack
			- 副本机制
		3. 消费者
			消费确认机制，自动提交偏移量
			幂等处理（重试机制）



11. mq的内部实现原理是啥？
	kafka pull模式（大部分都是pull模式，不用中心管理，客户端自己控制进度）

	topic 
		逻辑结构，实际上代表就是 多个partition（副本）
	partition
		副本
		一个partition代表多个segment
	broker
		一个kafka节点
	消费组
		topic会有多个消费组，消费组有多个消费者
		topic群发消息给多个消费组来实现订阅
			如何订阅？
	消费者

	生产者

	todo


12. mysql 隔离级别？如何实现的？
	事务基本属性 ACID
		原子性
		一致性
		持久性
		隔离性
	mysql隔离级别有四个
		读未提交
			啥也不管，会有脏读
		读已提交
			mvcc一致性视图按查询创建，能搞定脏读
		不可重复读
			mvcc一致性视图按事务创建，搞定不可重复读
		串行化
			加锁处理，串行化处理事务
	实现原理
		mysql执行更新插入都会有一个undolog，这些undolog可以用来被视图使用，生成一条记录的不同版本即为mvcc。
		mvcc的核心就是两个 一个 undolog和一致性视图，一致性视图来保存当前活跃的事务，视图保存当前活跃的所有事务id，undolog来保存数据---链表存储，数据行中会有事务id。

15. mysql幻读是什么？
	幻读现象就是一个事务因为其他事务导致多次查询给出不同的结果集

	rr级别（可重复读）已经尽可能规避了。
	比如快照读直接mvcc就规避了，当前读会通过间歇锁锁住相关，会阻塞其他事务的相关操作。
	问题是 一个事务A读取普通select，另外一个事务B插入一条数据并提交  A再更新这条事务会用到当前读，查不到却可以更新，即幻读。
	<!--  -->

13. redo log undolog binlog有啥用，区别是啥？
	binlog是mysql server层日志，主要做 归档处理。数据备份+主从同步
	redolog innodb存储引擎的日志，主要为了事务持久化
		mysql更新利用了Buffer Pool来提效(类似粉板记录流水再统一刷盘)，内存不可靠，需要redolog持久化
	undolog 实现事务的原子性，主要为了事务回滚和MVCC。


14. mysql 为啥要用B+树，不用B树，为啥不用 跳表？
	平衡多路查找树主要是为了减少磁盘读写次数，所以期望树呈矮胖结构。
	B数也是平衡多路查找树，和B+数的区别主要是 B+树叶子节点存储数据，其他数据不存数据，同时把叶子节点通过双向链表保存起来，方便范围查询。
	
	不用跳表的原因是跳表解决不了磁盘问题。redis因为是内存存储，所以检索效率一致的情况下是ok的。


16. mysql锁有哪些？各自的功能是啥？
	按范围来区分  1 全局锁  2 表锁   3 行锁
	按功能来区分
		1. 共享排他锁 
			表锁行锁都有  S锁 X锁   for share  即为读写锁
		2. 意向锁
			一种表锁，不与行锁冲突的表锁
			主要为了提速，加行锁的同时，也加一个表锁，避免需要遍历才知道数据才有行锁
		3. 记录锁
			行锁，记录某一行数据
		4. 间歇锁
			区间锁。
		5. 临键锁
			记录锁和间隙锁的组合
			锁区间是前开后闭，比如(5,10]。
		6. 插入意向锁
		7. 自增锁
			特殊的表锁
			自增主键相关的锁
			并不会阻塞事务，语句执行完毕即释放，不随着事务（id可能会不连续）

	


17. mysql主从同步模式？多机房部署同步怎么处理？循环复制问题？
	主从同步模式有三种
		1. 异步模式
			slave独立线程去拉取master的 binlog，不会干预事务线程的相关处理
		
		2. 同步模式
			master需要收到全部从库的ack，即从库也执行完事务，才能 返回客户端成功。

		3. 半同步模式
			master需要收到至少一个slave接受binlog并将binlog写入relaylog才返回客户端成功
	https://www.cnblogs.com/liboware/p/15302566.html
	多机房部署同步
		业务需要做单元化适配，两边数据都支持写入
		需要有唯一索引来做幂等处理
		唯一索引冲突需要引用全局唯一键来处理
		数据回环即循环复制问题 需要在回放binlog的事务上加一个写入操作来标识，后面收到这个binlog就不处理
	<!-- 没有循环复制，因为是slave去拉取master，不涉及双写同步问题 -->

	
19. redis有哪些基本数据结构
	对外
		string
		list对象
		Hash
		Set
		有序集合对象
	内部实现
		raw  int   embstr
		ziplist
		linkedlist双端列表
		hashtable字典
		intset整数集合
		skiplist


20. redis 跳表是什么样的数据结构？hashtable是啥样的？
	header字段代表开始节点
	tail代表尾节点
	level标识最大层数节点
	length表示节点总数

	节点字段
		forwardnode 	前节点
		span 			前节点跳过几个数据
		backnode 		后节点
		score			分值，具体值

	hashtable


21. lru怎么实现的？
	map  + 双向链表实现
	<!-- 
	struct LRU {
		kv map[string]*Node
		head *Node
		tail *Node
		capacity int
    	count int
	}
	
	struct Node {
		prev *Node
		next *Node
		val  int
		key  string
	}
	-->

22. redis内存过期策略有哪些？删除策略？
	过期策略
		1. 惰性过期
			即访问时判断时间戳进行过期处理
		2. 定期过期
			定时任务，默认100ms，随机抽取一定数量的key进行遍历删除，避免大IO
	内存删除策略
		定义：当redis内存不足时，主动删除部分key，保证稳定性
		策略模式：
			1. 不淘汰策略：不删除，内存不足则拒绝写入
			2. lru：设置了过期时间且最少使用的key删除
			3. 过期时间优先：按过期时间排序，优先删除快过期的
			4. 随机删除：设置了过期时间的随机删除
			5. 全局lru：全局最少使用
			6. 全局随机：全局随机

23. redis 主从同步是怎么做的？
	1. 通过长连接进行通信
	2. 同步模式
		- 全量同步 （rdb全量dump传送）
		- 增量同步
			- 会根据offset来决策是否要做同步
			- 主实例有两个结构
				replication buffer  记录同步的命令行（正常连接时的命令缓冲区）
				repl_backlog_buffer  记录未同步阻塞的命令行，环形结构，重叠了即需要全量同步（断联后的命令缓冲区）
			- 从实例有结构
				replication buffer  记录同步的命令行
	还有一种主从从的同步模式，降低主库消耗

24. redis 集群部署模型有哪些？
	集群部署（分布式）
	1. 客户端分片（原始）
	2. 分片逻辑独立到proxy层处理
		codis  （升级很费劲）
		twemproyx
	3. 服务端分片
		redis cluster
	主从模式（单节点）
		保证高可用				
	哨兵模式
		保证高可用
	哨兵模式+主从复制保证单节点高可用

25. redis 缓存失效会有哪些情况？怎么处理？ 
	缓存击穿 缓存雪崩 缓存穿透
	缓存击穿 - 热点数据过期
		1. 不给热点数据过期时间，后台异步刷新，或者监控热点数据的过期时间，快过期时，启动任务刷新缓存或重新设置过期时间
		2. 互斥锁方案，保证同一时间只有一个线程更新缓存，另外的协程要么等待后重新读取缓存，要么直接返回空对象
	缓存穿透 - 大量缓存未命中
		1. 布隆过滤器：粗暴过滤
			快速判断是否在数据结果中，避免无效请求
		2. 缓存空对象
	缓存雪崩 - 大量key过期，或者redis崩溃导致db崩溃
		1. redis高可用
		2. 限流降级（加锁或队列的方式保存存储）
		3. 数据预热
			- 让热点数据提前缓存，并随机过期时间，避免同时过期
			- 二级缓存 （同一个kv 一个短期一个长期）

26. redis 持久化怎么做的？
	aof
		append only file，追加命令操作模式
		会追加操作到aof缓冲区，再刷盘
		刷盘分三种模式
			1. 每个命令都需要刷盘（同步模式）
			2. 每一秒刷盘一次
			3. 不刷盘。默认30s刷盘
	rdb
		快照模式，对redis某个时刻的数据进行快照拷贝然后整个落盘备份。
		优点：恢复快，文件相对小
		有两个命令
			1. save  同步保存，会阻塞
			2. bgsave  后台处理，fork进程，利用linux写时复制机制。
	rdb + aof
		混合模式，
		rdb执行后会加后续的命令以aof的方式追加。redis4.0后才有的功能

27. redis 为啥这么快？
	1. 基于内存的单线程模型
	2. 网络io模型 epoll
	3. 内部各种优秀的数据结构设计。
	详细
	1. 基于内存吞吐，单线程无锁处理
	2. io多路复用，降低网络消耗，单线程可支持足够多的网络连接



28. 服务发现怎么处理的？
	这个会问嘛？细节不好说清
	服务注册  和打包系统相关联，获取所有的上下游
	服务发现 根据usn动态获取相关iplist，sdk直接请求
	控制台  可以根据集群配置相关调用信息

	最新的servermesh，让客户端更无感，避免版本升级的痛苦

29. 分布式锁有哪些实现？有啥优缺点
	方案1 基于mysql排他锁设计 
		即为select  for update
	方案2 基于redis setnx实现
		setnx成功抢占锁，执行完成后删除
	方案3 基于zookeeper实现
		zookeeper实现分布式锁存在一些缺陷。性能上不如基于缓冲（redis）实现分布式锁。
		每次创建锁和释放锁的过程中，都有动态创建，销毁瞬时节点来实现锁的功能
		且 zk中创建和删除节点都只能通过leader节点来执行，然后将数据同步到其他节点，分布式会有网络抖动，导致客户端和zk断联，此时zk服务端以为客户端挂了，会删除临时节点，其他客户端就可以获取分布式锁了，导致同时获取锁的不一致问题。
	redis问题
		过期时间处理会比较麻烦，而且需要针对value做随机处理，保证不会删除不是自己加的锁。


30. 分布式事务如何实现？
	2pc 
		准备阶段 提交阶段 二阶段。
	3pc
		cancommit precommit docommit三个阶段。
	tcc  优惠模型的各个实现
		try confirm cancel
	saga事务
		和tcc不同，不需要锁定，只不过需要支持回撤commit行为
	本地消息表 重点
		本地消息表方案应该是业界内使用最为广泛的，因为它使用简单，成本比较低。
		核心思路是将分布式事务拆分成本地事务进行处理。
		本地消息表与业务数据表处于同一个数据库中，
		这样就能利用本地事务来保证在对这两个表的操作满足事务特性，
		并且使用了消息队列来保证最终一致性。
		其执行过程如下：
		1. 上游处理完业务逻辑后，将业务数据和要下发的消息写入DB，同时发消息通知下游。
		2. 下游获取消息后，处理自己的业务逻辑；处理成功后，给上游发送处理通知，并修改本地消息状态；
		3. 上游有个定时任务，把未处理成功的消息，再次发送到消息中间件中；
		缺点：
		* 消息数据和业务数据耦合;
		* 如果没有封装好的解决方案，会有很多杂活需要处理。
	mq事务消息
		类似本地事务，只不过将本地事务表放入mq
		消息事务的原理是将两个事务通过消息中间件进行异步解耦 ，
		和本地消息表有点类似，但通过消息中间件的机制去做的，
		其本质就是将本地消息表封装到了消息中间件中。
		现在支持事务消息的消息中间件只有RocketMQ，这个概念最早也是RocketMQ提出的，
		适用于所有对数据最终一致性需求的场景。通过事务消息实现分布式事务的流程如下：
		* 发起方发送半事务消息会给RocketMQ ，此时消息的状态prepare，接受方还不能拉取到此消息；
		* 半事务消息发送成功后，执行本地事务；
		* 如果事务执行成功，则将消息commit，此时消费方能够接受到消息；
		* 如果事务执行失败，则回滚，消息中间件将这条prepare消息删除；
		* 如果事务参与方在执行完本地事务后宕机了
		* 这就需要消息队列集群具备回查机制：如果收到半事务消息后，在特定时间内没有再收到确认消息，
		* 会反过来请求事务参与方查询本地事务的执行状态，并给予反馈，决定是否将消息进行投递；
		* 消费端接收到消息后进行消费，如果消费失败（如网络不稳定，没有接受到消息，后者下游宕机），
		* 此时消息队列没有及时收到反馈，则会不断重试。 
		事务消息的本质的借鉴了二阶段提交的思想，它跟本地消息表的做法也很像，
		事务消息做的事情其实就是把消息表的存储和扫描消息表这两个事情放到消息中间件来做，使得消息表和业务表解耦。
		这种方案也是实现了 最终一致性，对比本地消息表实现方案，不需要再建消息表，不再依赖本地数据库事务了，
		所以这种方案更适用于高并发的场景。目前市面上实现该方案的只有阿里的RocketMQ。
	最大努力通知
		定期校对，对mq的补充，提供一个查询接口，如果没有主动消息，此时可以主动掉查询接口校对数据
31. es原理？
	很难说清

32. 其他存储了解过吗？hbase实现是啥？
	列式存储


33. 进程通信机制有哪些？
	socket
		与网络的socket一致，只不过不需要走网卡 走内核，更稳定
	共享内存

	信号量

	消息队列

	管道

	信号


34. 网络协议分层？timewait过多是啥？
	往细了问 会很痛苦
	应用层  http ftp dns
	运输层  tcp udp
	网络层  ip icmp
	数据链路层 ppp等等不懂了就
	物理层

	timewait：是因为频繁的关闭打开端口导致的。主动关闭的一方会有的状态
		解决：可以设计快速回收，可以将msl值缩减，容许time_wait状态接入新的socket



35. 网络io模型有哪些？原理是啥？
	异步io：不导致请求进程阻塞
	同步io：导致请求进程阻塞
	网络操作有两个基本操作
	1. 等待网络数据到达网卡->读取到核心缓冲区，数据在内核区准备好
	2. 从内核缓冲区复制数据到进程空间
	阻塞模型
		1&2都会阻塞
	非阻塞模型
		1不阻塞 2阻塞
	io多路复用
		1不阻塞 2阻塞 select epool都是这个
		1.文件描述符数量少
			select 使用整型数组存储文件描述符集合，而 epoll 使用红黑树存储，数量较大。
		2.性能开销大
			epoll_ctl 中为每个文件描述符指定了回调函数，并在就绪时将其加入到就绪列表，因此 epoll 不需要像 select 那样遍历检测每个文件描述符，只需要判断就绪列表是否为空即可。当于时间复杂度从 O(n) 降为 O(1)。此外，每次调用 select 时都需要向内核拷贝所有要监听的描述符集合，而 epoll 对于每个描述符，
		select/epoll 的优势并不是对于单个连接能处理得更好，而是在于性能更多的连接
	信号驱动
	异步io
		1&2都不阻塞


36. 营销中台怎么做的效率提升？整个事的难点是啥？怎么解的？
	情况
		人效提升
		系统效率提升

	难点
		事多人少，面对各个业务的需求，需求+case让人应接不暇，，人和系统处于恶性循环，约做越错，错多做多。
	解法
		对要做的事进行拆解排序。优先释放人力，做高优的事。高优的定义，稳定性>人效提升（长期有益）> 需求 > 平台化改造。这个地方也有商量的空间。比如特别高优的需求，得衡量下
	todo

37. 平台化建设，难点是啥？怎么解的？
	情况：
		1. 系统缺乏整体性，配置入口不收敛，比如产品线接入 需要各个系统各自接入，各自也都有自己的定义
		2. 系统配置能力弱，业务需求循环迭代，重复性工作大
	解法：
		分三步走
			第一步先做好券系统的配置化改造（决策路径是roi最高，因为券是整个公司最核心的营销抓手，变动最多，投入人力最大）
			第二步是对资产系统进行重构合并
			第三步是将整个营销体系打通，同时将券的配置化能力复用到其他模型（卡+随单）
		第一步
			结合历史需求+场景进行回溯，发现券的变动主要在1. 核销规则  2. 排序要求  3. 业务属性字段的存储与透出（券无感）
			对于核销规则相关，可以抽象出模块，针对不同业务线，可以配置不同模板，模板是规则的集合，规则可以通过配置化，需求迭代就不需要前后端改造了，关于规则的抽象，对于券而言，本质上就是一个 xxx 参数是否等于 xxx 或者是大于小于 xxx 或者是 in  某个集合。这些简单的操作类型是非常容易枚举且配置化的。对于参数而言，可以通过固定协议（map[string]string）高知上游，上游可以直接传入相关参数，就可以实现协议的不改造。此外，对于一些复杂场景也是可以通过组合运算实现配置化的，比如 当xxx = 1 且 yyy = 2 命中的一个规则。这些是可以抽象出一个树状逻辑计算链，配置的时候自定义入参（上游不需要传入该参数）+ 相应的计算链 + 计算链后的枚举， 当券有这类规则时，直接运用计算链，得出新值后放入自定义的入参集合中区做匹配。
		第二步
			资产迁移项目，对虚币类的系统进行合并。本质上都是一类的系统。支持虚币的发放，过期，核销，查询。（配置化主要是 下发渠道，过期策略，预算归属等）。系统复杂点主要是过期是绑定在充值流水上的属性，而且核销需要关联到具体充值的流水上（财务合算）。流水需要很细。
			过期是惰性过期+定时任务处理。
			数据迁移比较麻烦，因为数据为异构数据，且需要不停服更新
			分几步走
			1. 项目上线（新系统支持全部接口，老系统改造）
			2. 流量双写
				- 写流量转发 （1. 异步写 2. 同步写 ；选择2 的原因是2的坏处是耗时增加，不过上游耗时完全可忽略，还能保证强一致性和低开发成本）
					- 增加用户记录迁移表，标记新用户，新用户双写
			3. 全量迁移离线数据
				- 迁移后的数据进行打标处理，打标之后开启双写（会有开始迁移-迁移中-完成迁移三种状态。）
					- 过程中的数据再写入，有两种解法1 阻塞写  2 正常写 重新迁。 采取2
				- 支持多用户强制迁移接口（清空数据后再重新迁移，方便diff阶段重新迁移复用）
			3. 数据diff
				接口diff
					读接口流量回放，对返回结果进行diff
				数据diff
					1. 全量数据diff   hive里获取全量用户
					2. 增量数据diff   每日hive获取变更用户
					diff指标
						条数 1. 总条数  2. 核销数量  3. 过期数量
						金额 1. 可用余额 2. 历史累计使用金额  3. 累计过期金额
			4. 切读 & 切写
				双写是以老系统为准，切读需要先切成以双系统写入为准，上游重试保证强一致。
				先老系统，再新系统，都写入成功才返回结果，此时可以切读。（主要为了避免短时间写入后立马查询导致的不一致）。 失败需要回滚老系统事务。或者容许资损（多发，核销链路不会有问题，因为上游会有强重试机制，冻结解冻）。
			5. 停写 （不可回滚）
			6. 下线老系统（inrouter路由切换）


		第三步
			优惠中心的配置化，下面的模型抽象好后，可以在上层完成两个功能，串联整个体系 
				1，产品线接入 （包括该品类支持哪些优惠项） 
				2. 优惠产品的配置化（包括收银台怎么展示）
			其中优惠产品的定义是锚定收银台用户看到的具体优惠项（明确-易理解，早期概念是很混乱的，比如券有平台券+渠道券，其实在券是没差异的，根据券的规则不同来区分，导致整个请求链路非常奇怪）
			底下的模型，卡-券-随单-资产  都可以配置化生成新的优惠品类，同时配置其C端展示，是否过风控，等等属性，配置侧收敛，各个系统公用配置。
			此外 券的规则模板能力也复用到 随单 + 卡，实现了功能复用。随单+卡 与券公用一套规则引擎
			产品线接入也提供了统一的配置入口，生成统一文件，全局公用，降低业务接入成本。


38. 降本是怎么做的？怎么拆解的？难点是啥？解法是啥？
	难点：
		成本分析，技术调研，保证业务稳定的情况下用各种手段进行降本
	抓手：
		大头成本主要是db+下游请求+日志存储+redis+弹性云+hive存储+odin监控+woater等
		掐头策略，处理大头

		db： 大头成本
			过期无用数据
				线上只存储有效数据，设置过期归档策略。
			过期业务仍有用数据
				线上存储需要热更新数据，离线库存储过期数据。调研离线数据库的相关成本，选取合理的存储。（hbase tidb es  ob）
		odin监控
			对监控进行聚合，对host层面的数据进行聚合，降低监控曲线
		下游请求   大头成本
			主要是风控，对请求进行合并处理，减少重复请求。
		redis
			缩容，合理分配

39. 合规是怎么做的？难点是啥？解法是啥？
	难点：
		需要线上无感的情况下对线上百亿数据进行加密处理
	解法：
		分阶段（保证可回滚，安全可靠）
			阶段1  初始阶段  
				写明文，读明文 ，dba加字段
			阶段2
				双写明文密文，读明文  - 增量数据处理
			阶段3
				离线数据加密回溯
			阶段4 
				双写明文密文，读密文-you兜底+报警
			阶段5
				双写明文密文，读密文- 无兜底+有报警
			阶段6
				写密文，读密文
		离线加密过程控制速度
			第三方平台 离线任务用队列控制，控制并发写入速度。且有入口可以随时停止，可以继续进行


40. 分账是怎么做的？难点是啥？解法是啥？
	情况:
		链路复杂。1. 两个计算模块  2. 配置分散 
		主要是耦合计价和解耦计价的模式导致分账的逻辑散列在两个地方，很不收敛。导致的分账问题较多，需要做梳理&下沉。在计价系统从耦合切耦合 需要各个系统都做相关配置。
	难点：
		迁移难度大：分账业务场景复杂，10多个国家，30多种不同的模式
		风险高：如何保证安全稳定的迁移，迁移过程中的变动如何协同
	目标：
		统一配置（费用项相关配置，分账属性等）
		账单统一账单口径（分三分账单）
		收敛费用项的相关定义，统一配置入口。
	过程拆解
		对当前的分账模式进行抽象分析，对费用项进行归类处理 （第三方费用，滴滴费用，基础费用）,可以基于 国家+车型+城市维度的不同费用项配置。
		几套配置  费用项归属配置  费用项元类的比例配置。 运营配置+pm配置 各司其职
	落地
		现状梳理
			1. 对当前的分账现状进行梳理。
		方案设计
			1. 配置设计，对分账进行配置化处理，并提供配置版本号（供后续收银根据版本号查询使用）
		diff
			1. publiclog打印两边的分账结果，离线diff
				疫情会导致流量不足可能会存在场景覆盖率  --- 梳理典型的还有比较特殊的一些场景，人工抽查留意
				两边费用计算比如存在误差 --- 数仓那边会做相应的噪点忽略工作
				账单和收银的会存在个别的抽成逻辑不一致   --针对这个问题 我这边梳理了关键的指标数据，并给出计算公式及比对公式
		监控
			- 分账比例加载报警
			- 分账过程计算报警（极端阈值的报警，负向账单处理，平账计算处理）

41. 如何保证计价的准确性？相关的资金安全怎么处理的？
	计价的准确性主要从几个维度来处理
	1. 代码逻辑上
		- 收敛钱的所有计算口径，底层统一用一个公共包进行钱相关的计算。
	2. 计费策略上
		- 路径补偿策略
			超过3km无计价点则请求地图进行路径补偿
		- 计价点修正策略
			开始计费点会进行修正（参考发单点+司机计价前最后一个点）
		- 附加费限额策略
			针对各个国家，不同场景的附加费会有拦截限制（比如高速费不超过100之类）
	3. 完单监控
		- 针对大额账单有监控报警
		- 针对负费用账单有抹平+监控处理
		- 针对账单+费用细项，出账的最后会再次核算，保证账平


41. 资产迁移方案是啥？细节是啥？
	数据迁移比较麻烦，因为数据为异构数据，且需要不停服更新
	分几步走
	1. 项目上线（新系统支持全部接口，老系统改造）
	2. 流量双写
		- 写流量转发 （1. 异步写 2. 同步写 ；选择2 的原因是2的坏处是耗时增加，不过上游耗时完全可忽略，还能保证强一致性和低开发成本）
			- 增加用户记录迁移表，标记新用户，新用户双写
	3. 全量迁移离线数据
		- 迁移后的数据进行打标处理，打标之后开启双写（会有开始迁移-迁移中-完成迁移三种状态。）
			- 过程中的数据再写入，有两种解法1 阻塞写  2 正常写 重新迁。 采取2
		- 支持多用户强制迁移接口（清空数据后再重新迁移，方便diff阶段重新迁移复用）
	3. 数据diff
		接口diff
			读接口流量回放，对返回结果进行diff
		数据diff
			1. 全量数据diff   hive里获取全量用户
			2. 增量数据diff   每日hive获取变更用户
			diff指标
				条数 1. 总条数  2. 核销数量  3. 过期数量
				金额 1. 可用余额 2. 历史累计使用金额  3. 累计过期金额
	4. 切读 & 切写
		双写是以老系统为准，切读需要先切成以双系统写入为准，上游重试保证强一致。
		先老系统，再新系统，都写入成功才返回结果，此时可以切读。（主要为了避免短时间写入后立马查询导致的不一致）。 失败需要回滚老系统事务。或者容许资损（多发，核销链路不会有问题，因为上游会有强重试机制，冻结解冻）。
	5. 停写 （不可回滚）
	6. 下线老系统（inrouter路由切换）


	
42. cgo了解嘛？
	go可以调用so文件。本质就是动态链接库怎么交互的
	对于go而言就是调用了一个系统调用

43. 设计模式相关？
	核心：开闭原则：面向扩展开放，面对修改关闭 （所有设计模式都是围绕这个处理的）
	
	创建型模式（单例模式、工厂模式）
	结构型模式（适配器模式、装饰模式）
	行为型模式（责任链模式、迭代器模式）

	报件中心的难点：报件信息的合规要求多种多样。不同的机构要求不同。
	报件中心的解法：策略模式，


44. 接口幂等怎么处理？
	1. 唯一索引 （查询+保存）
		根据业务定义一个唯一索引
		接口调用根据能否插入成功来确认是否第一次，
	2. 数据库乐观锁（查询+删除=更新即删除）
		版本处理
		update tablename set version+1 where version=x
	3. redis setnx  （查询保存）
		接口唯一健设置到redis中，设置成功正常执行，设置失败则按重复接口处理
	4. redis token机制 （查询删除）
		服务端提供生成token接口，上游可以来获取token，服务端会将token放入redis中，请求携带token过来会服务端删除token ，如果删除失败则认为是重复请求

45. redis缓存更新的过程
	写策略
		先更新数据
		再删key（顺序不能调换，不然会有脏缓存）
	读策略
		命中则直接返回
		不命中则查询数据库缓存后返回
	不能保证绝对一致，如果要绝对一致需要用分布式锁或者队列处理，或者更新数据的时候也更新缓存同时降低缓存有效期
	比如一个请求查询未命中缓存，另外一个请求同时修改并删除缓存，A请求在B执行后再写入缓存会出现问题


99. 未来展望
	还是希望能继续成长，锻炼发现问题解决问题的能力
		一方面是技术成长，主要以架构能力技术能力为主。 
		一方面是带人，帮人成长，其实这个过程中也会锻炼自己的其他能力，微观来说有查漏补缺，宏观来说可以在管理方向有所成长。
	
	管理的基础是要让老板对这一堆事放心。需要有足够的把控，对人力安排要做到心理有数，把事与人做好关联
		1. 需要带领团队，牵引团队的方向，包括不局限团队的工作重心，大的架构技术方案决策，人力分配
		2. 需要给团队兜底，有问题需要做好兜底。
		3. 帮组 组员成长，可以是方向类的，也可以是细节类的，可以是技术上的，也可以是做事方法的，当好质检员，有时候需要当坏人





算法相关：
	> 本质：1. 穷举（如何聪明的穷举） 2. 数学推导后的变种算法
	> 按照不同数据结构，会有不同的一些技巧和方法论

1. 数组和字符串
	- 二分查找（本质其实是双指针）
	- 滑动窗口（快慢指针）
	- 回文串技巧
	- 前置和技巧（解决子数组问题）
		- 用另外一个数组存储数组0-i之和的问题。方便缓存
	- 查分数组
		diff[i] = src[i] - src[i-1]  可以根据diff推出src
2. 链表
	- 快慢指针（双指针）
	- 虚拟头指针
	- 递归处理？
3. 树
	- DFS遍历（深度遍历）
		- 前序： 根左右  中序：  左根右   后序：  左右根
	- BFS遍历（广度遍历，一层一层打印）
		- 需要队列，按层出队打印
4. 技巧
	- 回溯算法
		1. 路径：记录已经选择的问题  2. 选择列表：可以选择做的选择 3. 结束条件：到达决策树的末尾
范式
func backstrack(args) {
	if 决策树末尾 {
		return 
	}
	for item in 选择列表 {
		判断是否有效
		dsth 做选择
		ret = backstrack(args)
		dsth 回撤选择
	}
	return ret
}


	- 动态规划
		1. 确定状态：状态为主问题和子问题的变量 2. 确定dp函数的定义  3. 明确选择 4. 明确bad case

范式
func dopfunc(args){
	dp := xxxx
	for i in 状态值 {
		for j in 选择列表 {
			dp[i] = fn(dp[i-n])  //fn值需要做的处理
		}
	}
}







