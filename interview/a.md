
1. 解决的难题


buglist
	数据库堵死
		1. 单表单行写tps大于1000 导致数据库堵死
			mysql单表单行写入不支持过高tps，原因是可执行的sql会在排队（等待单行的锁），导致链接释放不及时，链接被打满，或者cpu占用过高（死锁检测等也会大量消耗cpu）
			https://segmentfault.com/a/1190000044390396

			解法
				db升级，支持限流

		2. 单用户绑券大于1w
			业务原因，绑券后再来查询，会扫表，扫描大量行，导致cpu被大量占用


			解法
				db设置最大执行时间
				业务侧设置固定时间检测处理大量绑券问题



	并发写string导致问题
		string的操作是异步的 先写len再写data，携程a写了 length 携程b来读 这时候会按新length来读取就会数组越界。




2. 典型项目

	- 当前项目的整体框架
		- 细节实现
		- 技术难点
			不停服对异构数据进行迁移，保证业务无感


资产迁移
	- 技术难点
		不停服对异构数据进行迁移，保证业务无感
	步骤
		1. 代码上线 
			- 保证新服务支持写接口，同时有开关控制逻辑
		2. 存量数据同步
			- 将历史库的数据同步指新服务
			- 更新用户状态为已同步（打开双写开关，返回以老系统写入为主，偶先失败需要流量录制）
		3. 流量双写
			随着2的持续进行  3 自动进行
		4. 线上diff
			- 接口diff （读接口全流量diff）
			- 数据diff（离线对新老db的数据进行diff，梳理关键指标，通过两边接口实现即可）
		5. 切读 & 切写
			- 切主写   以双系统为准的写，主写新，需要做超时导致的旧系统失败的流量录制，保证最终数据一致性处理
			- 切读（核心接口，需要与切主写同一个开关操作，即读写均以新系统为准） 
			- 切读（其他查询接口）

		7. 停写（不可回滚）

		8. 下线



3. 服务拆分
	原则
		- 暂无


		需要经过与业务专家进行一些列的讨论，头脑风暴，可以借助如事件风暴，用例分析法，名次动词法，四色建模法等活动后获得一系列相关联的对象，可形成庞大的关系图

	案例：
		比如优惠开关再收银去实现还是优惠中心去实现---边界划分：按功能的定义&模块的职责定义来区分

